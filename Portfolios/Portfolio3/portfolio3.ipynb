{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qiFqSbrkXD9"
      },
      "source": [
        "## **Portfolio 3: Exploring WordNet**\n",
        "\n",
        "###### *Author: Shreya Valaboju*\n",
        "###### *Section: CS 4395.001*\n",
        "\n",
        "###### *Execute the notebook from top to bottom. For more info, refer to readme_portfolio3.txt* \n",
        "\n",
        "\n",
        "\n",
        "WordNet is a lexical database popularly used for computational lingustics and natural language processing. Nouns, verbs, adjectives, and adverbs are grouped into sets of synonyms, also known as \"synsets.\" These synsets are organized hierarchically through hypernyms, hyponyms, holonyms, meronyms, etc. This notebook explores basic functionality of WordNet using nltk. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "23nxU40bHGGj",
        "outputId": "1d587d42-add1-4ee6-82a4-370ff8c9ff0d"
      },
      "outputs": [],
      "source": [
        "# import/download necessary libraries\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.book import text4\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import sentiwordnet as swn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT0OSZjc54K8"
      },
      "source": [
        "#### 1. Synsets for Nouns and Verbs\n",
        "Let's explore how WordNet is organized for nouns and verbs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL0OwufRPv9X"
      },
      "source": [
        "##### Nouns: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lAwtJ7cVl2rL",
        "outputId": "f8597467-7c7d-4b99-c337-1c65a5ba935b"
      },
      "outputs": [],
      "source": [
        "# all synsets for a noun, 'elephant'\n",
        "wn.synsets('elephant')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X35m_Ef-emeA"
      },
      "outputs": [],
      "source": [
        "# choose 1 synset out of all for the noun\n",
        "elephant_synset = wn.synset('elephant.n.01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wH_oH4XytUUU",
        "outputId": "1372734e-e2ea-4d64-a188-ed9f401c2fd1"
      },
      "outputs": [],
      "source": [
        "# extract definition, usage, lemmas if possible\n",
        "print('Definition: ', elephant_synset.definition())\n",
        "print('Usage: ', elephant_synset.examples())\n",
        "print('Lemmas: ', elephant_synset.lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lzY8ehu_nL8H",
        "outputId": "d667627c-e2bd-4abb-f99a-da3ad8e51b5b"
      },
      "outputs": [],
      "source": [
        "# traverse hiearchy of the synset for the noun (naive approach)\n",
        "hyp = elephant_synset.hypernyms()[0] # hypernyms give a broader word or synset the noun falls under\n",
        "top = wn.synset('entity.n.01') # stop once the highest hiearchy synset is reached\n",
        "\n",
        "while hyp: # keep finding hypernyms (synsets above)\n",
        "  print(hyp)\n",
        "  if hyp==top:\n",
        "    break\n",
        "  if hyp.hypernyms():\n",
        "    hyp = hyp.hypernyms()[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wz3ToM5jqYj-",
        "outputId": "339e3d58-ddca-486e-8ca7-354dafdf1aca"
      },
      "outputs": [],
      "source": [
        "#print hypernyms, hyponyms, meronyms,holonyms, antonyms\n",
        "\n",
        "print('Hypernyms: ', elephant_synset.hypernyms())\n",
        "print('Hyponyms: ', elephant_synset.hyponyms())\n",
        "\n",
        "\n",
        "# not all nouns have holonyms, meronyms, or antonyms. \n",
        "if elephant_synset.member_holonyms():\n",
        "  print('Holonyms: ', elephant_synset.member_holonyms())\n",
        "else:\n",
        "  print('Holonyms: ',list())\n",
        "\n",
        "if elephant_synset.part_meronyms():\n",
        "  print('Meronyms: ', elephant_synset.part_meronyms())\n",
        "else:\n",
        "  print('Meronyms: ',list())\n",
        "\n",
        "\n",
        "ant=[] # holds all antonyms found\n",
        "# iterate through the synset's lemmas to find any antonyms\n",
        "for lemma in elephant_synset.lemmas():\n",
        "  if lemma.antonyms():\n",
        "    ant.append(lemma.antonyms()[0].name())\n",
        "print('Antonyms: ',ant)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmgzvCP3Qqe_"
      },
      "source": [
        "WordNet organizes nouns through synsets. In this example, we saw that the noun, 'elephant' had synsets placed above in its hiearchy. Similarly, nouns in WordNet are connected through defining hypernyms(higher), hyponyms(lower), meronym(part of), holonym(whole), and troponyms(specific action) synsets. Nouns are the most highly connected synsets. In addition, not all nouns have all the types of relations, for instance, a noun may not have a meronym.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm46J2nynXAd"
      },
      "source": [
        "##### Verbs: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Gtgiq8N8s8Z1",
        "outputId": "a9108c73-9a76-48df-ef67-ccc0af9c753f"
      },
      "outputs": [],
      "source": [
        "# explore synsets for a verb\n",
        "wn.synsets('snoring')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T0hkYDVisRr"
      },
      "outputs": [],
      "source": [
        "# pick a synset for the verb, 'snore'\n",
        "snore_synset = wn.synset('snore.v.01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ynpqkjnqtRO4",
        "outputId": "375e07a5-15db-434e-b48e-0a439090c9cb"
      },
      "outputs": [],
      "source": [
        "# extract definition, usage, lemmas if possible\n",
        "print('Definition: ', snore_synset.definition())\n",
        "print('Usage: ', snore_synset.examples())\n",
        "print('Lemmas: ', snore_synset.lemmas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "N6zJGRUxteCF",
        "outputId": "c3cd1c65-1be4-44e9-f6b5-fab1292ab054"
      },
      "outputs": [],
      "source": [
        "# traverse hiearchy (more sophisticated method)\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(snore_synset.closure(hyper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IkuOEPePx45A",
        "outputId": "97e2dd2f-4064-4fb2-cb82-9d3e99a74ad7"
      },
      "outputs": [],
      "source": [
        "# Use morphy to find as many different forms of the word(verb) \n",
        "print(wn.morphy('snoring', wn.VERB))\n",
        "print(wn.morphy('snoring', wn.NOUN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg5YUb-OQ8dv"
      },
      "source": [
        "WordNet organizes verbs similarly as it does with nouns, through synsets and hierarchy. As we saw with the example, 'snore,' verbs can be in hypernym/hyponym relations. Specifically, 'breathe' was a hypernym of snore. However, lemmas are something to note with verbs. The lemma form of 'snore' could have also bee considered a noun. So, when evaluating/analyzing a verb, it is important to pick the synset that implies that the lemma is intended to a verb. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqvVK09zO_Xn"
      },
      "source": [
        "#### 2. Similarity between 2 Words\n",
        "Using various metrics and algorithms to calculate how similar words are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_qV1ptp5AGR"
      },
      "outputs": [],
      "source": [
        "# pick 2 similar words, select synsets for each\n",
        "person = wn.synset('person.n.01')\n",
        "human = wn.synset('homo.n.02')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "POzFn6xh6GDO",
        "outputId": "9e01dd31-eebd-456c-8c98-c594e61a7476"
      },
      "outputs": [],
      "source": [
        "# Calculate Wu-Palmer Similarity metric\n",
        "wn.wup_similarity(person, human)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xCiGXR-l6O89",
        "outputId": "1a764645-34ce-4d0c-de9a-7b220d8bd028"
      },
      "outputs": [],
      "source": [
        "# Run the Lesk Algorithm on 'person'\n",
        "sent_person = ['That', 'person', 'is','my','friend','.']\n",
        "print(lesk(sent_person, 'person', 'n'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YgEWBJ0I65SG",
        "outputId": "af13d97d-e4f5-4f85-e0fa-80b0007a65ba"
      },
      "outputs": [],
      "source": [
        "# Run Lesk Algorithm on 'human'\n",
        "sent_human = ['The','species','is','human','.'] # here is an example sentence where human is used in it.\n",
        "print(lesk(sent_human, 'human', 'n'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_PDIMkQREvg"
      },
      "source": [
        "The Wu-Palmer similarity metric calculates similarity between 2 words by using the depths of the 2 synsets related in the WordNet hierarchy. On the other hand, the Lesk Algorithm looks at context and compares dictionary glosses for word overlap and count to determine the similar synset. From running the blocks above, we can see that the 2 words, 'person' and 'human' are fairly similar, giving us a Wu-Palmer metric score of 0.57. We would expect the similarity to be higher, but we can conclude that maybe the hierarchies for the respective synsets are slightly different. Next, the Lesk Algorithm outputted expected synsets for the 2 words afer using them in sentences. Ther results were expected as both were nouns and the names of the synsets were the exact same. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hp6rZabPFJX"
      },
      "source": [
        "#### 3. Senti-WordNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-VQdMF_RQF8"
      },
      "source": [
        "Senti-WordNet is built on top of WordNet. It is used to further analyze the sentiment, positive or negative and objective or subjective given some text. Senti-WordNet assigns a positive, negative, and objective score. Sentiment analysis is a popular method for many use cases. For example, Senti-WordNet, as an NLP tool, can be used to analyze and improve customer service, social media, or market research given a body of text or words. The few cells below demonstrate how senti-wordnet is used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c77gUrUk8O7m",
        "outputId": "799e5566-9bee-4bec-c878-d7496fd3b219"
      },
      "outputs": [],
      "source": [
        "# choose an 'emotionally charged' word\n",
        "wn.synsets('rage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sidWhuuD8qsy"
      },
      "outputs": [],
      "source": [
        "suffer_synset = wn.synset('rage.n.02')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iSeFxUNI9Adn",
        "outputId": "7e8a2153-9401-4d94-93cd-ba602f4fa2a1"
      },
      "outputs": [],
      "source": [
        "# get senti-synsets for the emotionally charged word\n",
        "senti_suffer = swn.senti_synsets('rage','n')\n",
        "for item in senti_suffer:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "W7E2B40_9qPF",
        "outputId": "d8ba9492-ccf8-4e67-d43a-eff63853a8eb"
      },
      "outputs": [],
      "source": [
        "# output polarity scores for each senti-synset\n",
        "\n",
        "for s in swn.senti_synsets('rage','n'):\n",
        "  print(s)\n",
        "  print(\"negative: \", s.neg_score())\n",
        "  print(\"positive: \", s.pos_score())\n",
        "  print(\"objective: \", s.obj_score())\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8SHLXIU9Rksy",
        "outputId": "63d142c1-0775-48c3-94c1-0a52b9fa9076"
      },
      "outputs": [],
      "source": [
        "# Make up a sentence. Output the polarity for each word in the sentence. (stop words not removed, may need to remove)\n",
        "sentence = 'women expressed intense rage '\n",
        "neg=0\n",
        "pos=0\n",
        "tokens = sentence.split() # split the sentence into tokens\n",
        "\n",
        "print(\"Polarity for each word in the sentence: '\",sentence, \"'\\n\")\n",
        "\n",
        "#iterate through each token and print polarity of each token \n",
        "for t in tokens:\n",
        "  word_syn = list(swn.senti_synsets(t))[0] # pick the first senti-synset\n",
        "  polarity = word_syn.pos_score() - word_syn.neg_score() # calculate polarity but taking the difference between the positive and negative score\n",
        "  print(t,\": \", polarity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OLfPa9gRZ2K"
      },
      "source": [
        "Here are some interesting observations, knowing our emotionally charged word, 'rage.' In our sentence, the words 'women' and 'expressed' have a neutral sentiment, while 'intense' and 'rage' had negative. These results were mostly expected, although I did predict 'rage' to have a more negative score than just -.25. However, we can observe that variances in scores are possible based on the senti-synset selected with its respective positive and negative scoring. Further, such scores are important in NLP because they allow to better understand and leverage sentiment. Polarity tells use how strong the sentiment is for a particular word. This could be highly useful in determining overall sentiment and what particular words/areas of text are projecting more intense emotion/sentiment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yR5UaZXPKHq"
      },
      "source": [
        "#### 4. Text Collocations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlhoMWbASFOD"
      },
      "source": [
        "A collocation is when 2 more combine and if any word is substituted by chance, we cannot get the intended/correct meaning. For example, the collocation, 'strong tea,' does not mean the tea is muscular or can lift heavy. Collocations can be found using 'PMI' or point-wise mutual information. If PMI = 0, the 2 words are independent. If PMI > 0, then there is a likely collocation and vice versa if PMI < 0. Let's take a closer look at collocations in WordNet. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OjxPEgz_8Nte",
        "outputId": "0821a702-7bb2-4ee2-a8d4-4bfff20a1981"
      },
      "outputs": [],
      "source": [
        "# collocations for text4\n",
        "text4.collocations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ftdYq7ahVJMj",
        "outputId": "784faefd-9f50-4585-e54c-4746fbecfa9e"
      },
      "outputs": [],
      "source": [
        "# join text into 1 string and lowercase for convenience\n",
        "text = ' '.join(text4.tokens).lower() \n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q9l9cGrzyDNE",
        "outputId": "aee9a516-3b67-4362-b721-f67bad341d93"
      },
      "outputs": [],
      "source": [
        "# choose 1 collocation, calculate mutual information (P(x,y) / [P(x) * P(y)])\n",
        "collocation = 'chief justice'\n",
        "collocation_first='chief'\n",
        "collocation_last='justice'\n",
        "\n",
        "# mutual information formula is the  log of the probability: P(x,y) / [P(x) * P(y)]\n",
        "\n",
        "vocab_size = len(set(text4))\n",
        "prob_cj = text.count(collocation)/vocab_size\n",
        "print(\"P('chief justice'): \",prob_cj)\n",
        "\n",
        "prob_c = text.count(collocation_first)/vocab_size\n",
        "print(\"P('chief'): \",prob_c)\n",
        "\n",
        "prob_j = text.count(collocation_last)/vocab_size\n",
        "print(\"P('justice'): \",prob_j)\n",
        "\n",
        "pmi = math.log2(prob_cj / (prob_c * prob_j)) # log of the probability of the collocation / probabilities of collocation word 1 and 2 each multiplied\n",
        "print('PMI = ', pmi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmyBEFxASNEt"
      },
      "source": [
        "From our results, we can observe that the words 'chief justice,' is likely a collocation as its PMI score is positive and well over 0. The two words also had a low probability or occurrence in the text, as those values are close to 0. We can infer that lower probabilities of words, especially grouped togther, can likely be collocations. Meaning, let's say we wanted to find the mutual information of 'the people.' The word 'the' would appear many times, and so would 'people.' A hypothesis would be that the PMI is lower and since those words are used literally as well. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lL0OwufRPv9X",
        "Sm46J2nynXAd",
        "NqvVK09zO_Xn",
        "-yR5UaZXPKHq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d867657525dd03eadb0f15a5bb0c750c4a4de4ef60ab6748337b15b866bf106c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
