{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification and Analysis using Deep Learning\n",
        "\n",
        "##### By: Shreya Valaboju\n",
        "##### Section: CS 4395.001\n",
        "##### * Before executing this notebook, ensure all necessary libraries/modules are installed. Simply run the notebook from top to bottom. "
      ],
      "metadata": {
        "id": "o1UOi_MTxq7g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcgYDGkexedI"
      },
      "source": [
        "The dataset is used to solve a multi-class classification problem, classifying emails as fraud, commerical spam, phishing, or none (false-positive). This dataset is dervied from Kaggle, and is called \"Phishing Email Data by Type.\" In this notebook, we will try to train our model using various algorithms, such as a simple sequential model, Recurrent Neural Network (RNN), and a Convolutional Neural Network (CNN), to be able to predict whether a given email message is fraud, commerical spam, phishing, or none (false-positive). The dataset has 3 columns: 'Subject', 'Text', and 'Type.'The 'Text' column holds the entire email message. The subject of the emails is also another attribute in the dataset, however, in this notebook we will only be using the \"Text\" and \"Type\" columns. We will vectorize the \"Text\" column to derive the features for the model and the \"Type\" will represent our target class. This project builds on the previous 'Text Classification using Naive Bayes, Logistic Regression, and Neural Network' notebook and uses the same dataset. Here is the link to the dataset: \n",
        "https://www.kaggle.com/datasets/charlottehall/phishing-email-data-by-type\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQZWxI5qxedJ"
      },
      "source": [
        "#### 1. Import Libraries and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i0e1y6GYP23",
        "outputId": "1adddabd-9cba-4acd-96ca-37c0a661cfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import text \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "l-iB4Xy5epUj",
        "outputId": "21b62430-c751-4882-cc46-5ac44dcdd4bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Subject  \\\n",
              "0           URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
              "1                  URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
              "2                                      GOOD DAY TO YOU   \n",
              "3                                     from Mrs.Johnson   \n",
              "4                                         Co-Operation   \n",
              "..                                                 ...   \n",
              "154                 These Bags Just Arrived For Spring   \n",
              "155  POTUS Comes to Broadway this April! Get Ticket...   \n",
              "156                       Let’s talk about Bridgerton!   \n",
              "157                    MONDAY MIX: All eyes on Ukraine   \n",
              "158  The DOTD is back on with 15% off a lightning-f...   \n",
              "\n",
              "                                                  Text             Type  \n",
              "0    URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...            Fraud  \n",
              "1    Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...            Fraud  \n",
              "2    FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...            Fraud  \n",
              "3    Goodday Dear\\n\\n\\nI know this mail will come t...            Fraud  \n",
              "4    FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...            Fraud  \n",
              "..                                                 ...              ...  \n",
              "154  Bags so perfect—you'll never want to be withou...  Commercial Spam  \n",
              "155  INAUGURAL BROADWAY PERFORMANCE APRIL 14\\r\\nA N...  Commercial Spam  \n",
              "156  GET THE BEST OF EVERYTHING IN THE APP\\n\\nSTARB...  Commercial Spam  \n",
              "157  Hi!\\n \\nSpring forward with our newest noPac c...  Commercial Spam  \n",
              "158  Hi,  | PLAYER MEMBER | 0 Points\\n\\nEarn And Sa...  Commercial Spam  \n",
              "\n",
              "[159 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9d648c8-eb94-4418-88aa-cc2de0a68760\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Text</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
              "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
              "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOOD DAY TO YOU</td>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>from Mrs.Johnson</td>\n",
              "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Co-Operation</td>\n",
              "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>These Bags Just Arrived For Spring</td>\n",
              "      <td>Bags so perfect—you'll never want to be withou...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>POTUS Comes to Broadway this April! Get Ticket...</td>\n",
              "      <td>INAUGURAL BROADWAY PERFORMANCE APRIL 14\\r\\nA N...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Let’s talk about Bridgerton!</td>\n",
              "      <td>GET THE BEST OF EVERYTHING IN THE APP\\n\\nSTARB...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>MONDAY MIX: All eyes on Ukraine</td>\n",
              "      <td>Hi!\\n \\nSpring forward with our newest noPac c...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>The DOTD is back on with 15% off a lightning-f...</td>\n",
              "      <td>Hi,  | PLAYER MEMBER | 0 Points\\n\\nEarn And Sa...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9d648c8-eb94-4418-88aa-cc2de0a68760')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9d648c8-eb94-4418-88aa-cc2de0a68760 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9d648c8-eb94-4418-88aa-cc2de0a68760');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# get a text classification dataset (hosted on a public url via github)\n",
        "data_url = \"https://raw.githubusercontent.com/shreyavala/nlp_text_classification_data/main/phishing_data_by_type.csv\"\n",
        "df=pd.read_csv(data_url)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape(Rows, Columns): \",df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvK1Unft4j7k",
        "outputId": "abeb0137-6c03-4b17-be77-0a24d6178b6b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape(Rows, Columns):  (159, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "awobAxzGxedN",
        "outputId": "c24b2180-ea79-4694-db2c-e1c021cc9001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fb1ae149970>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# creates a graph showing the distribution of the target classes\n",
        "\n",
        "sns.catplot(data=df, kind='count', x='Type', height=4, aspect=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ1zFTotxedN"
      },
      "source": [
        "From this distribution we can see that the classes are fairly balanced. There is a proportional number of instances between Fraud, Phishing, False Positives, and Commerical Spam emails. We do not need to undersample or oversample any class in this dataset. This dataset it relatively small, with 159 instances and 3 attributes. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "xuY21A0brlYn",
        "outputId": "b1a69d57-8e00-4347-a5d8-7f4fc715dbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-a91182193439>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Text'] = df['Text'].str.replace('[^\\w\\s]','') # remove punctuation\n",
            "<ipython-input-63-a91182193439>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Text'] = df['Text'].str.replace('\\d+', '') # remove numbers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Subject  \\\n",
              "0           URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
              "1                  URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
              "2                                      GOOD DAY TO YOU   \n",
              "3                                     from Mrs.Johnson   \n",
              "4                                         Co-Operation   \n",
              "..                                                 ...   \n",
              "154                 These Bags Just Arrived For Spring   \n",
              "155  POTUS Comes to Broadway this April! Get Ticket...   \n",
              "156                       Let’s talk about Bridgerton!   \n",
              "157                    MONDAY MIX: All eyes on Ukraine   \n",
              "158  The DOTD is back on with 15% off a lightning-f...   \n",
              "\n",
              "                                                  Text             Type  \n",
              "0    urgent business assistance and partnershipdear...            Fraud  \n",
              "1    dear friendi am mr ben suleman a custom office...            Fraud  \n",
              "2    from his royal majesty hrm crown ruler of elem...            Fraud  \n",
              "3    goodday deari know this mail will come to you ...            Fraud  \n",
              "4    from mr godwin akwesitel  fax  before i introd...            Fraud  \n",
              "..                                                 ...              ...  \n",
              "154  bags so perfectyoull never want to be without ...  Commercial Spam  \n",
              "155  inaugural broadway performance april \\ra new c...  Commercial Spam  \n",
              "156  get the best of everything in the appstarbucks...  Commercial Spam  \n",
              "157  hi spring forward with our newest nopac course...  Commercial Spam  \n",
              "158  hi   player member   pointsearn and save moreb...  Commercial Spam  \n",
              "\n",
              "[159 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbdc4196-ca54-4c87-b274-6d686ee17c27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Text</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
              "      <td>urgent business assistance and partnershipdear...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
              "      <td>dear friendi am mr ben suleman a custom office...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOOD DAY TO YOU</td>\n",
              "      <td>from his royal majesty hrm crown ruler of elem...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>from Mrs.Johnson</td>\n",
              "      <td>goodday deari know this mail will come to you ...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Co-Operation</td>\n",
              "      <td>from mr godwin akwesitel  fax  before i introd...</td>\n",
              "      <td>Fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>These Bags Just Arrived For Spring</td>\n",
              "      <td>bags so perfectyoull never want to be without ...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>POTUS Comes to Broadway this April! Get Ticket...</td>\n",
              "      <td>inaugural broadway performance april \\ra new c...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>Let’s talk about Bridgerton!</td>\n",
              "      <td>get the best of everything in the appstarbucks...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>MONDAY MIX: All eyes on Ukraine</td>\n",
              "      <td>hi spring forward with our newest nopac course...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>The DOTD is back on with 15% off a lightning-f...</td>\n",
              "      <td>hi   player member   pointsearn and save moreb...</td>\n",
              "      <td>Commercial Spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbdc4196-ca54-4c87-b274-6d686ee17c27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbdc4196-ca54-4c87-b274-6d686ee17c27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbdc4196-ca54-4c87-b274-6d686ee17c27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# preprocess the 'Text' column (lowercase, remove punctuation and numbers)\n",
        "df['Text'] = df['Text'].str.lower() # lower\n",
        "df['Text'] = df['Text'].str.replace('[^\\w\\s]','') # remove punctuation\n",
        "df['Text'] = df['Text'].str.replace('\\n','') # remove newlines\n",
        "df['Text'] = df['Text'].str.replace('\\t','') # remove tabs\n",
        "df['Text'] = df['Text'].str.replace('\\d+', '') # remove numbers\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "o-qLRezd8gbY",
        "outputId": "99f7e289-c850-4950-9b36-06c27891dd4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    abacha  abandoned  abidjan  able    abroad  academic    accept  accepted  \\\n",
              "0  0.00000        0.0      0.0   0.0  0.000000       0.0  0.000000       0.0   \n",
              "1  0.14028        0.0      0.0   0.0  0.000000       0.0  0.000000       0.0   \n",
              "2  0.00000        0.0      0.0   0.0  0.070671       0.0  0.000000       0.0   \n",
              "3  0.00000        0.0      0.0   0.0  0.200996       0.0  0.000000       0.0   \n",
              "4  0.00000        0.0      0.0   0.0  0.000000       0.0  0.068949       0.0   \n",
              "\n",
              "   access  accordance  ...     youas      youi  youll  young  youre  youth  \\\n",
              "0     0.0         0.0  ...  0.000000  0.000000    0.0    0.0    0.0    0.0   \n",
              "1     0.0         0.0  ...  0.000000  0.000000    0.0    0.0    0.0    0.0   \n",
              "2     0.0         0.0  ...  0.000000  0.000000    0.0    0.0    0.0    0.0   \n",
              "3     0.0         0.0  ...  0.000000  0.000000    0.0    0.0    0.0    0.0   \n",
              "4     0.0         0.0  ...  0.083368  0.065382    0.0    0.0    0.0    0.0   \n",
              "\n",
              "   youtube  youve  zip  𝘧𝘳𝘰𝘮  \n",
              "0      0.0    0.0  0.0   0.0  \n",
              "1      0.0    0.0  0.0   0.0  \n",
              "2      0.0    0.0  0.0   0.0  \n",
              "3      0.0    0.0  0.0   0.0  \n",
              "4      0.0    0.0  0.0   0.0  \n",
              "\n",
              "[5 rows x 1251 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ea21a08-fdaa-4eb2-9e6f-b94f0847ebd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abacha</th>\n",
              "      <th>abandoned</th>\n",
              "      <th>abidjan</th>\n",
              "      <th>able</th>\n",
              "      <th>abroad</th>\n",
              "      <th>academic</th>\n",
              "      <th>accept</th>\n",
              "      <th>accepted</th>\n",
              "      <th>access</th>\n",
              "      <th>accordance</th>\n",
              "      <th>...</th>\n",
              "      <th>youas</th>\n",
              "      <th>youi</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>youre</th>\n",
              "      <th>youth</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>zip</th>\n",
              "      <th>𝘧𝘳𝘰𝘮</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.14028</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070671</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083368</td>\n",
              "      <td>0.065382</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1251 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ea21a08-fdaa-4eb2-9e6f-b94f0847ebd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ea21a08-fdaa-4eb2-9e6f-b94f0847ebd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ea21a08-fdaa-4eb2-9e6f-b94f0847ebd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# use tf-idf vectorization to extract features (tf-idf frequencies) and preprocess by lemmatization\n",
        "class LemmaTokenizer:\n",
        "     def __init__(self):\n",
        "         self.wnl = WordNetLemmatizer()\n",
        "     def __call__(self, doc):\n",
        "         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words = 'english',tokenizer=LemmaTokenizer(),min_df=3) # intitialize a tf-idf vectorizer (with stopwords removal and lemmatization)\n",
        "\n",
        "vectorized_data = vectorizer.fit_transform(df['Text'].values.astype('U')) # tell the vectorizer to read our data\n",
        "\n",
        "# construct a dataframe with vectorized words (dataframe will be large)\n",
        "df_vectorized= pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "df_vectorized.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8lIBubpxedM"
      },
      "source": [
        "#### 2. Train/Test Split w/ Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w55DLZZlr4Ib",
        "outputId": "1eb331f1-0ad4-400d-8161-526d548378f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0]\n",
            "X shape:  (119, 1251) (40, 1251)\n",
            "y shape:  (119,) (40,)\n"
          ]
        }
      ],
      "source": [
        "# train/test split with encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df_vectorized  # drop any other columns/features deemed unecessary for the X\n",
        "y = df[\"Type\"] # target class\n",
        "\n",
        "# add an encoder for the target class, categorical -> numerical \n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "print(y_encoded)\n",
        "\n",
        "# split train/test \n",
        "x_train, x_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded,test_size = 0.25,random_state = 42) # split data into 75% train, 25% test\n",
        "\n",
        "print(\"X shape: \", x_train.shape, x_test.shape)\n",
        "print(\"y shape: \", y_train_encoded.shape, y_test_encoded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUiUPGIqxedO"
      },
      "source": [
        "#### 3. Run and Evaluate Sequential, RNN, CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries for deep learning models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Dropout, Embedding, LSTM, Dense\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "Di78NTNw0ovv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### A. Sequential Model"
      ],
      "metadata": {
        "id": "s27m__C70gjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build and fit the model\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
        "model.add(layers.Dense(4, activation='softmax',kernel_initializer='normal')) # use softmax bc we have 4 target classes"
      ],
      "metadata": {
        "id": "iKZAwt3KFlBF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ye3XZOmszmZs"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtSh-qlUzz17",
        "outputId": "ff4150d7-0e4e-49c7-f1fa-d85e8dbd0981"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 74ms/step - loss: 1.3857 - accuracy: 0.2710 - val_loss: 1.3851 - val_accuracy: 0.2500\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3772 - accuracy: 0.5140 - val_loss: 1.3833 - val_accuracy: 0.4167\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.3695 - accuracy: 0.6449 - val_loss: 1.3811 - val_accuracy: 0.4167\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.3604 - accuracy: 0.7664 - val_loss: 1.3783 - val_accuracy: 0.4167\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.3497 - accuracy: 0.8224 - val_loss: 1.3743 - val_accuracy: 0.4167\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.3375 - accuracy: 0.8692 - val_loss: 1.3695 - val_accuracy: 0.4167\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.3223 - accuracy: 0.8879 - val_loss: 1.3629 - val_accuracy: 0.4167\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.3049 - accuracy: 0.8879 - val_loss: 1.3557 - val_accuracy: 0.4167\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.2847 - accuracy: 0.9159 - val_loss: 1.3472 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.2632 - accuracy: 0.9252 - val_loss: 1.3376 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.2379 - accuracy: 0.9252 - val_loss: 1.3266 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.2110 - accuracy: 0.9252 - val_loss: 1.3155 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1808 - accuracy: 0.9346 - val_loss: 1.3038 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1487 - accuracy: 0.9626 - val_loss: 1.2911 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1149 - accuracy: 0.9626 - val_loss: 1.2773 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0787 - accuracy: 0.9813 - val_loss: 1.2620 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.0418 - accuracy: 0.9907 - val_loss: 1.2453 - val_accuracy: 0.5833\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.0027 - accuracy: 0.9907 - val_loss: 1.2290 - val_accuracy: 0.5833\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9623 - accuracy: 0.9907 - val_loss: 1.2111 - val_accuracy: 0.5833\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9218 - accuracy: 0.9907 - val_loss: 1.1927 - val_accuracy: 0.6667\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8807 - accuracy: 0.9907 - val_loss: 1.1742 - val_accuracy: 0.6667\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.8398 - accuracy: 0.9907 - val_loss: 1.1570 - val_accuracy: 0.6667\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7996 - accuracy: 0.9907 - val_loss: 1.1409 - val_accuracy: 0.6667\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7601 - accuracy: 0.9907 - val_loss: 1.1222 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.7211 - accuracy: 0.9907 - val_loss: 1.1030 - val_accuracy: 0.6667\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6829 - accuracy: 0.9907 - val_loss: 1.0856 - val_accuracy: 0.6667\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6463 - accuracy: 0.9907 - val_loss: 1.0693 - val_accuracy: 0.6667\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6106 - accuracy: 0.9907 - val_loss: 1.0545 - val_accuracy: 0.6667\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5770 - accuracy: 1.0000 - val_loss: 1.0400 - val_accuracy: 0.7500\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5438 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7500\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.5128 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.7500\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4832 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4547 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.7500\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4282 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4032 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7500\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3563 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.7500\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3350 - accuracy: 1.0000 - val_loss: 0.9237 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3147 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.7500\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2963 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2782 - accuracy: 1.0000 - val_loss: 0.8947 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2616 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 0.7500\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2465 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.8719 - val_accuracy: 0.7500\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2070 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.7500\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1955 - accuracy: 1.0000 - val_loss: 0.8539 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1851 - accuracy: 1.0000 - val_loss: 0.8487 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.8435 - val_accuracy: 0.7500\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.8389 - val_accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1aafe0520>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict \n",
        "import numpy as np\n",
        "y_test_pred = model.predict(x_test)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1) # get the correct, encoded labels\n",
        "\n",
        "y_test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpXtxISN8U22",
        "outputId": "8a448f11-6cb8-41ff-b398-df8c8d6d1700"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 3, 1, 2, 0, 3, 1, 0, 2, 1, 2, 3, 2, 2, 0, 1, 1, 2, 1, 2,\n",
              "       2, 2, 2, 0, 1, 0, 0, 0, 0, 3, 3, 0, 2, 1, 3, 3, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy score: ', accuracy_score(y_test_encoded, y_test_pred))\n",
        "print('precision score: ', precision_score(y_test_encoded, y_test_pred, average = 'macro')) # macro because we have equal classes\n",
        "print('recall score: ', recall_score(y_test_encoded, y_test_pred, average = 'macro'))\n",
        "print('f1 score: ', f1_score(y_test_encoded, y_test_pred, average = 'macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jez0XIgE9PIQ",
        "outputId": "fcb1a311-37a7-4d9e-a0f9-2734293f2575"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score:  0.85\n",
            "precision score:  0.8625\n",
            "recall score:  0.8636363636363636\n",
            "f1 score:  0.8459789712986643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### B. RNN"
      ],
      "metadata": {
        "id": "sOvqlbgA-NUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add padding and re-split train/test\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "max_len = 100 # max length of sequences\n",
        "X = pad_sequences(df_vectorized.values.tolist(), maxlen=max_len, padding='post', truncating='post')\n",
        "print(X.shape)\n",
        "\n",
        "# re-add encoding\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "print(y_encoded)\n",
        "\n",
        "x_train, x_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded,test_size = 0.25,random_state = 42) # split data into 75% train, 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQHlSvIg-S9X",
        "outputId": "f7e7003c-40a8-40d5-8738-3ab7a5795bfd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(159, 100)\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a Sequential model with Embedding and SimpleRNN layers and embedding\n",
        "import tensorflow_hub as hub\n",
        "dropout_rate = 0.2  # might help overfitting\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "model2 = models.Sequential()\n",
        "model2.add(layers.Embedding(vocab_size, 64))\n",
        "model2.add(layers.SimpleRNN(32))\n",
        "model2.add(Dropout(dropout_rate))\n",
        "model2.add(layers.Dense(4, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "TI2snNhm-Yg-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "uLjOW3EcGdpr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and train\n",
        "model2.fit(x_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir6gUt0bGk8r",
        "outputId": "5da37416-3827-4e1c-ce50-66d400db22a5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 133ms/step - loss: 1.3996 - accuracy: 0.2150 - val_loss: 1.4010 - val_accuracy: 0.1667\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.3975 - accuracy: 0.2523 - val_loss: 1.4062 - val_accuracy: 0.1667\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1.3908 - accuracy: 0.2430 - val_loss: 1.3890 - val_accuracy: 0.1667\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3934 - accuracy: 0.2243 - val_loss: 1.4077 - val_accuracy: 0.1667\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.4006 - accuracy: 0.2617 - val_loss: 1.4084 - val_accuracy: 0.1667\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3923 - accuracy: 0.2897 - val_loss: 1.3934 - val_accuracy: 0.1667\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.3942 - accuracy: 0.2523 - val_loss: 1.3877 - val_accuracy: 0.1667\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.3923 - accuracy: 0.2056 - val_loss: 1.4083 - val_accuracy: 0.1667\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1.3951 - accuracy: 0.2336 - val_loss: 1.4039 - val_accuracy: 0.1667\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3950 - accuracy: 0.2617 - val_loss: 1.4115 - val_accuracy: 0.1667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1a487a460>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict \n",
        "import numpy as np\n",
        "y_test_pred = model2.predict(x_test)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1) # get the correct, encoded labels\n",
        "\n",
        "y_test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnL64-zBJ0pC",
        "outputId": "76062a84-8faa-48be-e0fa-db3876a555d1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi9HwiDlJ8Vk",
        "outputId": "05265f5b-8fa9-4b71-9e30-8df43c7611e3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        11\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.28      1.00      0.43        11\n",
            "\n",
            "    accuracy                           0.28        40\n",
            "   macro avg       0.07      0.25      0.11        40\n",
            "weighted avg       0.08      0.28      0.12        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### C. CNN"
      ],
      "metadata": {
        "id": "EBjCVncR-S-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build a Sequential model 1D convnet\n",
        "model3 = models.Sequential()\n",
        "vocab_size = len(vectorizer.vocabulary_)\n",
        "model3.add(layers.Embedding(vocab_size, output_dim = 128, input_length=max_len)) \n",
        "model3.add(layers.Conv1D(32, 7, activation='relu', kernel_regularizer=regularizers.l2(0.01))) \n",
        "model3.add(layers.MaxPooling1D(5)) \n",
        "model3.add(layers.Conv1D(32, 7, activation='relu', kernel_regularizer=regularizers.l2(0.01))) \n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(4, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "nFtkon6dLIHJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model3.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Cl23ER0zLtWO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit and train\n",
        "model3.fit(x_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aax05KBOL4PZ",
        "outputId": "3b0a33fd-d14f-4c9f-ecf4-1555ec4a5720"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 99ms/step - loss: 1.8098 - accuracy: 0.2243 - val_loss: 1.4515 - val_accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.4204 - accuracy: 0.2336 - val_loss: 1.4043 - val_accuracy: 0.1667\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1.3942 - accuracy: 0.2523 - val_loss: 1.3929 - val_accuracy: 0.1667\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1.3912 - accuracy: 0.1963 - val_loss: 1.3951 - val_accuracy: 0.1667\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3892 - accuracy: 0.2056 - val_loss: 1.3945 - val_accuracy: 0.1667\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3893 - accuracy: 0.1869 - val_loss: 1.3984 - val_accuracy: 0.1667\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3884 - accuracy: 0.2243 - val_loss: 1.4006 - val_accuracy: 0.1667\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3877 - accuracy: 0.2523 - val_loss: 1.4045 - val_accuracy: 0.1667\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.3870 - accuracy: 0.2523 - val_loss: 1.4047 - val_accuracy: 0.1667\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.3876 - accuracy: 0.2243 - val_loss: 1.3987 - val_accuracy: 0.1667\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3877 - accuracy: 0.1589 - val_loss: 1.4000 - val_accuracy: 0.1667\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3870 - accuracy: 0.2150 - val_loss: 1.4018 - val_accuracy: 0.1667\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3873 - accuracy: 0.1963 - val_loss: 1.4017 - val_accuracy: 0.1667\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3871 - accuracy: 0.2523 - val_loss: 1.3978 - val_accuracy: 0.1667\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3876 - accuracy: 0.2523 - val_loss: 1.3945 - val_accuracy: 0.1667\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3874 - accuracy: 0.2523 - val_loss: 1.3935 - val_accuracy: 0.1667\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3872 - accuracy: 0.2430 - val_loss: 1.3931 - val_accuracy: 0.1667\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3867 - accuracy: 0.2150 - val_loss: 1.3916 - val_accuracy: 0.1667\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3878 - accuracy: 0.2150 - val_loss: 1.3945 - val_accuracy: 0.1667\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3874 - accuracy: 0.2523 - val_loss: 1.3967 - val_accuracy: 0.1667\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3881 - accuracy: 0.2150 - val_loss: 1.3987 - val_accuracy: 0.1667\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.3875 - accuracy: 0.1776 - val_loss: 1.3948 - val_accuracy: 0.1667\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.3879 - accuracy: 0.2243 - val_loss: 1.3918 - val_accuracy: 0.1667\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3871 - accuracy: 0.2430 - val_loss: 1.3966 - val_accuracy: 0.1667\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3871 - accuracy: 0.2056 - val_loss: 1.3955 - val_accuracy: 0.1667\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.3872 - accuracy: 0.2430 - val_loss: 1.3953 - val_accuracy: 0.1667\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3877 - accuracy: 0.2523 - val_loss: 1.3946 - val_accuracy: 0.1667\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3865 - accuracy: 0.2430 - val_loss: 1.3938 - val_accuracy: 0.1667\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3871 - accuracy: 0.2523 - val_loss: 1.3906 - val_accuracy: 0.1667\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.3869 - accuracy: 0.2523 - val_loss: 1.3904 - val_accuracy: 0.1667\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1.3870 - accuracy: 0.2243 - val_loss: 1.3935 - val_accuracy: 0.1667\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.3868 - accuracy: 0.2523 - val_loss: 1.3925 - val_accuracy: 0.1667\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1.3874 - accuracy: 0.2523 - val_loss: 1.3892 - val_accuracy: 0.1667\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1.3886 - accuracy: 0.1963 - val_loss: 1.3923 - val_accuracy: 0.1667\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1.3884 - accuracy: 0.2523 - val_loss: 1.3893 - val_accuracy: 0.1667\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1.3871 - accuracy: 0.2523 - val_loss: 1.3914 - val_accuracy: 0.1667\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.3867 - accuracy: 0.2056 - val_loss: 1.3958 - val_accuracy: 0.1667\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.3878 - accuracy: 0.2523 - val_loss: 1.3986 - val_accuracy: 0.1667\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 1.3871 - accuracy: 0.2056 - val_loss: 1.3971 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 1.3875 - accuracy: 0.2150 - val_loss: 1.3960 - val_accuracy: 0.1667\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.3867 - accuracy: 0.2523 - val_loss: 1.3948 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.3873 - accuracy: 0.2523 - val_loss: 1.3968 - val_accuracy: 0.1667\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 1.3871 - accuracy: 0.2523 - val_loss: 1.3993 - val_accuracy: 0.1667\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.3870 - accuracy: 0.2523 - val_loss: 1.3943 - val_accuracy: 0.1667\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.3876 - accuracy: 0.2523 - val_loss: 1.3965 - val_accuracy: 0.1667\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 1.3871 - accuracy: 0.2336 - val_loss: 1.3952 - val_accuracy: 0.1667\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 51ms/step - loss: 1.3874 - accuracy: 0.2523 - val_loss: 1.3914 - val_accuracy: 0.1667\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 1.3879 - accuracy: 0.1776 - val_loss: 1.3882 - val_accuracy: 0.1667\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 1.3871 - accuracy: 0.2523 - val_loss: 1.3909 - val_accuracy: 0.1667\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 1.3875 - accuracy: 0.1963 - val_loss: 1.3910 - val_accuracy: 0.1667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1a4c29b50>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict \n",
        "y_test_pred = model3.predict(x_test)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=1) # get the correct, encoded labels\n",
        "\n",
        "y_test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wrRzJ7NfaG",
        "outputId": "0cf03a4b-da28-4594-d626-707adc496e45"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_encoded, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC7rpNHnNfOk",
        "outputId": "dd50e688-82de-4fa2-e853-47d29dd2a8aa"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.43        11\n",
            "           1       0.00      0.00      0.00         7\n",
            "           2       0.00      0.00      0.00        11\n",
            "           3       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.28        40\n",
            "   macro avg       0.07      0.25      0.11        40\n",
            "weighted avg       0.08      0.28      0.12        40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Analysis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LE-6c3aI3s2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running Deep Learning on a small dataset produced interesting results which make sense. The dataset used was very small, and overal performed extremely poor using RNN and CNN. However, when using a simple sequential model, the accuracy was fairly high, over 80%, this also includes precision, recall, and F1 for all the 4 target classes. \n",
        "\n",
        "The simple sequential model performed very well given our small, balanced dataset. This is probably due to the fact that it is less likely to overfit/overlearn the small data. There are less hyper-parameters to tune and it is therefore less likely to overfit and overlearn during training. I learned that for simple datasets, deep learning does not provide good results. \n",
        "\n",
        "For RNN and CNNs, a large about data is required. We have 159 instances and 4 classes, so it is expected to perform poorly. Even though I added padding and tried L2 regularization, the RNN and CNN both still predicted the same class for all instances in the test sets, resulting in accuracies less than 30%. It seems like both RNN and CNN overfitted to a point when it performed very badly on the test data. Additionally, there are too many hyper-parameters to adjust, leading to overlearning during training. I should have used a dataset with more training examples. For the CNN, I saw that changing the learning rate from 1e-4 or 0.01 helped the loss actually decrease. The variances in recall and precision are probably due to the fact that the model was unable to train on sufficient data for that class. Both RNN and CNN were good at detecting/classifying for one class whether an email was fraud/spam/phishing, but it has a low precision, which means that even though it may have said an email is fraud/spam/phishing, it is not likely that is actually is. It is good at detecting positive cases in general but not reliable. "
      ],
      "metadata": {
        "id": "-ZwhD8SzNROL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}